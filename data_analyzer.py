#!/usr/bin/env python3
"""
data_analyzer.py - ë°ì´í„° ë¶„ì„ ìœ í‹¸ë¦¬í‹°

CSV íŒŒì¼ì˜ ê¸°ë³¸ì ì¸ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
pandas ì—†ì´ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import csv
import math
import argparse
from typing import List, Dict, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from collections import Counter, defaultdict
from pathlib import Path


@dataclass
class ColumnStats:
    """ì—´ì˜ í†µê³„ ì •ë³´"""
    name: str
    dtype: str  # 'numeric', 'string', 'mixed'
    count: int
    missing: int
    unique: int
    
    # ìˆ«ìí˜•ì¼ ê²½ìš°
    min_val: Optional[float] = None
    max_val: Optional[float] = None
    mean: Optional[float] = None
    median: Optional[float] = None
    std_dev: Optional[float] = None
    sum_val: Optional[float] = None
    
    # ë¬¸ìí˜•ì¼ ê²½ìš°
    top_values: List[Tuple[str, int]] = field(default_factory=list)


@dataclass
class DataSummary:
    """ë°ì´í„°ì…‹ ìš”ì•½ ì •ë³´"""
    filename: str
    rows: int
    columns: int
    column_names: List[str]
    column_stats: Dict[str, ColumnStats]
    sample_rows: List[Dict[str, Any]]


class DataAnalyzer:
    """
    CSV ë°ì´í„° ë¶„ì„ í´ë˜ìŠ¤
    
    pandas ì—†ì´ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œìœ¼ë¡œ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, filepath: str, encoding: str = "utf-8"):
        """
        Args:
            filepath: CSV íŒŒì¼ ê²½ë¡œ
            encoding: íŒŒì¼ ì¸ì½”ë”© (ê¸°ë³¸ê°’: utf-8)
        """
        self.filepath = Path(filepath)
        self.encoding = encoding
        self.data: List[Dict[str, Any]] = []
        self.columns: List[str] = []
        
        self._load_data()
    
    def _load_data(self) -> None:
        """CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        encodings_to_try = [self.encoding, "utf-8", "cp949", "euc-kr", "latin-1"]
        
        for enc in encodings_to_try:
            try:
                with open(self.filepath, "r", encoding=enc, newline="") as f:
                    # êµ¬ë¶„ì ìë™ ê°ì§€
                    sample = f.read(4096)
                    f.seek(0)
                    
                    # êµ¬ë¶„ì ì¶”ì¸¡
                    delimiter = ","
                    for delim in [",", "\t", ";", "|"]:
                        if sample.count(delim) > sample.count(delimiter):
                            delimiter = delim
                    
                    reader = csv.DictReader(f, delimiter=delimiter)
                    self.columns = reader.fieldnames or []
                    self.data = list(reader)
                    self.encoding = enc
                    return
            except (UnicodeDecodeError, UnicodeError):
                continue
        
        raise ValueError(f"íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.filepath}")
    
    def _is_numeric(self, value: str) -> bool:
        """ê°’ì´ ìˆ«ìì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        if not value or value.strip() == "":
            return False
        try:
            float(value.replace(",", ""))
            return True
        except (ValueError, AttributeError):
            return False
    
    def _to_numeric(self, value: str) -> Optional[float]:
        """ê°’ì„ ìˆ«ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not value or value.strip() == "":
            return None
        try:
            return float(value.replace(",", ""))
        except (ValueError, AttributeError):
            return None
    
    def _calculate_stats(self, values: List[float]) -> Dict[str, float]:
        """ìˆ«ì ë¦¬ìŠ¤íŠ¸ì˜ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not values:
            return {}
        
        n = len(values)
        sorted_vals = sorted(values)
        
        mean = sum(values) / n
        
        # ì¤‘ì•™ê°’
        mid = n // 2
        if n % 2 == 0:
            median = (sorted_vals[mid - 1] + sorted_vals[mid]) / 2
        else:
            median = sorted_vals[mid]
        
        # í‘œì¤€í¸ì°¨
        if n > 1:
            variance = sum((x - mean) ** 2 for x in values) / (n - 1)
            std_dev = math.sqrt(variance)
        else:
            std_dev = 0
        
        return {
            "min": min(values),
            "max": max(values),
            "mean": mean,
            "median": median,
            "std_dev": std_dev,
            "sum": sum(values),
        }
    
    def get_column_stats(self, column: str) -> ColumnStats:
        """íŠ¹ì • ì—´ì˜ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if column not in self.columns:
            raise ValueError(f"ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {column}")
        
        values = [row.get(column, "") for row in self.data]
        
        # ê²°ì¸¡ì¹˜ ê³„ì‚°
        missing = sum(1 for v in values if not v or v.strip() == "")
        
        # ê³ ìœ ê°’ ìˆ˜
        unique = len(set(v for v in values if v and v.strip()))
        
        # ìˆ«ìí˜• ì—¬ë¶€ íŒë‹¨
        numeric_values = [self._to_numeric(v) for v in values]
        numeric_values = [v for v in numeric_values if v is not None]
        
        numeric_ratio = len(numeric_values) / len(values) if values else 0
        
        stats = ColumnStats(
            name=column,
            dtype="numeric" if numeric_ratio > 0.8 else "string",
            count=len(values),
            missing=missing,
            unique=unique
        )
        
        if stats.dtype == "numeric" and numeric_values:
            calc_stats = self._calculate_stats(numeric_values)
            stats.min_val = calc_stats.get("min")
            stats.max_val = calc_stats.get("max")
            stats.mean = calc_stats.get("mean")
            stats.median = calc_stats.get("median")
            stats.std_dev = calc_stats.get("std_dev")
            stats.sum_val = calc_stats.get("sum")
        else:
            # ë¬¸ìí˜•: ë¹ˆë„ ìƒìœ„ ê°’
            counter = Counter(v for v in values if v and v.strip())
            stats.top_values = counter.most_common(5)
        
        return stats
    
    def get_summary(self) -> DataSummary:
        """ë°ì´í„°ì…‹ ì „ì²´ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        column_stats = {}
        for col in self.columns:
            column_stats[col] = self.get_column_stats(col)
        
        return DataSummary(
            filename=self.filepath.name,
            rows=len(self.data),
            columns=len(self.columns),
            column_names=self.columns,
            column_stats=column_stats,
            sample_rows=self.data[:5]
        )
    
    def describe(self) -> str:
        """pandasì˜ describe()ì™€ ìœ ì‚¬í•œ ì¶œë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        summary = self.get_summary()
        
        lines = []
        lines.append(f"íŒŒì¼: {summary.filename}")
        lines.append(f"í–‰ ìˆ˜: {summary.rows:,}")
        lines.append(f"ì—´ ìˆ˜: {summary.columns}")
        lines.append("")
        
        # ìˆ«ìí˜• ì—´ í†µê³„
        numeric_cols = [s for s in summary.column_stats.values() if s.dtype == "numeric"]
        if numeric_cols:
            lines.append("ğŸ“Š ìˆ«ìí˜• ì—´ í†µê³„:")
            lines.append("-" * 80)
            
            # í—¤ë”
            headers = ["", "count", "mean", "std", "min", "median", "max"]
            lines.append(f"{headers[0]:15} {headers[1]:>10} {headers[2]:>12} {headers[3]:>12} {headers[4]:>12} {headers[5]:>12} {headers[6]:>12}")
            lines.append("-" * 80)
            
            for s in numeric_cols:
                lines.append(
                    f"{s.name[:15]:15} {s.count - s.missing:>10} "
                    f"{s.mean:>12.2f} {s.std_dev:>12.2f} "
                    f"{s.min_val:>12.2f} {s.median:>12.2f} {s.max_val:>12.2f}"
                )
        
        lines.append("")
        
        # ë¬¸ìí˜• ì—´ í†µê³„
        string_cols = [s for s in summary.column_stats.values() if s.dtype == "string"]
        if string_cols:
            lines.append("ğŸ“ ë¬¸ìí˜• ì—´ í†µê³„:")
            lines.append("-" * 60)
            
            for s in string_cols:
                lines.append(f"\n{s.name}:")
                lines.append(f"  - ìœ íš¨ê°’: {s.count - s.missing:,} / ê²°ì¸¡: {s.missing:,}")
                lines.append(f"  - ê³ ìœ ê°’: {s.unique:,}")
                if s.top_values:
                    top_str = ", ".join(f"{v}({c})" for v, c in s.top_values[:3])
                    lines.append(f"  - ìƒìœ„ê°’: {top_str}")
        
        return "\n".join(lines)
    
    def filter(self, column: str, condition: str, value: Any) -> List[Dict[str, Any]]:
        """
        ì¡°ê±´ì— ë§ëŠ” í–‰ì„ í•„í„°ë§í•©ë‹ˆë‹¤.
        
        Args:
            column: í•„í„°ë§í•  ì—´
            condition: ì¡°ê±´ (eq, ne, gt, lt, ge, le, contains)
            value: ë¹„êµ ê°’
            
        Returns:
            í•„í„°ë§ëœ í–‰ ëª©ë¡
        """
        if column not in self.columns:
            raise ValueError(f"ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {column}")
        
        results = []
        
        for row in self.data:
            cell_value = row.get(column, "")
            numeric_cell = self._to_numeric(cell_value)
            
            match = False
            
            if condition == "eq":
                match = cell_value == str(value) or (numeric_cell is not None and numeric_cell == float(value))
            elif condition == "ne":
                match = cell_value != str(value)
            elif condition == "gt" and numeric_cell is not None:
                match = numeric_cell > float(value)
            elif condition == "lt" and numeric_cell is not None:
                match = numeric_cell < float(value)
            elif condition == "ge" and numeric_cell is not None:
                match = numeric_cell >= float(value)
            elif condition == "le" and numeric_cell is not None:
                match = numeric_cell <= float(value)
            elif condition == "contains":
                match = str(value).lower() in cell_value.lower()
            
            if match:
                results.append(row)
        
        return results
    
    def group_by(self, column: str, agg_column: Optional[str] = None) -> Dict[str, Any]:
        """
        ì—´ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
        
        Args:
            column: ê·¸ë£¹í™” ê¸°ì¤€ ì—´
            agg_column: ì§‘ê³„í•  ì—´ (ì„ íƒì )
            
        Returns:
            ê·¸ë£¹ë³„ ì§‘ê³„ ê²°ê³¼
        """
        if column not in self.columns:
            raise ValueError(f"ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {column}")
        
        groups: Dict[str, List[Dict]] = defaultdict(list)
        
        for row in self.data:
            key = row.get(column, "(ë¹ˆê°’)")
            groups[key].append(row)
        
        if agg_column and agg_column in self.columns:
            # ìˆ«ìí˜• ì§‘ê³„
            result = {}
            for key, rows in groups.items():
                values = [self._to_numeric(r.get(agg_column, "")) for r in rows]
                values = [v for v in values if v is not None]
                
                if values:
                    result[key] = {
                        "count": len(rows),
                        "sum": sum(values),
                        "mean": sum(values) / len(values),
                        "min": min(values),
                        "max": max(values),
                    }
                else:
                    result[key] = {"count": len(rows)}
            return result
        else:
            # ë‹¨ìˆœ ì¹´ìš´íŠ¸
            return {key: len(rows) for key, rows in groups.items()}
    
    def correlation(self, col1: str, col2: str) -> Optional[float]:
        """ë‘ ìˆ«ìí˜• ì—´ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if col1 not in self.columns or col2 not in self.columns:
            raise ValueError("ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        pairs = []
        for row in self.data:
            v1 = self._to_numeric(row.get(col1, ""))
            v2 = self._to_numeric(row.get(col2, ""))
            if v1 is not None and v2 is not None:
                pairs.append((v1, v2))
        
        if len(pairs) < 2:
            return None
        
        n = len(pairs)
        x_vals = [p[0] for p in pairs]
        y_vals = [p[1] for p in pairs]
        
        mean_x = sum(x_vals) / n
        mean_y = sum(y_vals) / n
        
        numerator = sum((x - mean_x) * (y - mean_y) for x, y in pairs)
        denom_x = math.sqrt(sum((x - mean_x) ** 2 for x in x_vals))
        denom_y = math.sqrt(sum((y - mean_y) ** 2 for y in y_vals))
        
        if denom_x == 0 or denom_y == 0:
            return None
        
        return numerator / (denom_x * denom_y)
    
    def to_csv(self, filepath: str, rows: Optional[List[Dict]] = None) -> None:
        """ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        data_to_write = rows if rows is not None else self.data
        
        with open(filepath, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=self.columns)
            writer.writeheader()
            writer.writerows(data_to_write)
    
    def head(self, n: int = 5) -> List[Dict[str, Any]]:
        """ì²˜ìŒ nê°œ í–‰ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.data[:n]
    
    def tail(self, n: int = 5) -> List[Dict[str, Any]]:
        """ë§ˆì§€ë§‰ nê°œ í–‰ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.data[-n:]
    
    def value_counts(self, column: str) -> List[Tuple[str, int]]:
        """ì—´ì˜ ê°’ ë¹ˆë„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if column not in self.columns:
            raise ValueError(f"ì—´ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {column}")
        
        values = [row.get(column, "") for row in self.data]
        return Counter(values).most_common()


def create_histogram(values: List[float], bins: int = 10, width: int = 50) -> str:
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ íˆìŠ¤í† ê·¸ë¨ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not values:
        return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    min_val = min(values)
    max_val = max(values)
    
    if min_val == max_val:
        return f"ëª¨ë“  ê°’ì´ ë™ì¼: {min_val}"
    
    bin_width = (max_val - min_val) / bins
    bin_counts = [0] * bins
    
    for v in values:
        idx = min(int((v - min_val) / bin_width), bins - 1)
        bin_counts[idx] += 1
    
    max_count = max(bin_counts) if bin_counts else 1
    
    lines = []
    for i, count in enumerate(bin_counts):
        start = min_val + i * bin_width
        end = start + bin_width
        bar_len = int(count / max_count * width)
        bar = "â–ˆ" * bar_len
        lines.append(f"{start:10.2f} - {end:10.2f} | {bar} ({count})")
    
    return "\n".join(lines)


def print_table(rows: List[Dict[str, Any]], columns: List[str], max_col_width: int = 20) -> None:
    """ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not rows:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì—´ ë„ˆë¹„ ê³„ì‚°
    col_widths = {}
    for col in columns:
        max_width = len(col)
        for row in rows[:50]:  # ì²˜ìŒ 50í–‰ë§Œ í™•ì¸
            val = str(row.get(col, ""))
            max_width = max(max_width, min(len(val), max_col_width))
        col_widths[col] = min(max_width, max_col_width)
    
    # í—¤ë”
    header = " | ".join(col[:col_widths[col]].ljust(col_widths[col]) for col in columns)
    separator = "-+-".join("-" * col_widths[col] for col in columns)
    
    print(header)
    print(separator)
    
    # ë°ì´í„°
    for row in rows:
        values = []
        for col in columns:
            val = str(row.get(col, ""))[:max_col_width]
            values.append(val.ljust(col_widths[col]))
        print(" | ".join(values))


def main():
    """ë©”ì¸ CLI í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ğŸ“Š ë°ì´í„° ë¶„ì„ ìœ í‹¸ë¦¬í‹°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python data_analyzer.py data.csv                    # ë°ì´í„° ìš”ì•½
  python data_analyzer.py data.csv --describe         # ìƒì„¸ í†µê³„
  python data_analyzer.py data.csv --head 10          # ì²˜ìŒ 10í–‰
  python data_analyzer.py data.csv --column age       # íŠ¹ì • ì—´ í†µê³„
  python data_analyzer.py data.csv --filter "age gt 30"  # í•„í„°ë§
  python data_analyzer.py data.csv --group city       # ê·¸ë£¹í™”
  python data_analyzer.py data.csv --hist age         # íˆìŠ¤í† ê·¸ë¨
  python data_analyzer.py data.csv --corr age salary  # ìƒê´€ê³„ìˆ˜
        """
    )
    
    parser.add_argument("file", help="CSV íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--describe", "-d", action="store_true",
                        help="ìƒì„¸ í†µê³„ ì¶œë ¥")
    parser.add_argument("--head", type=int, metavar="N",
                        help="ì²˜ìŒ Nê°œ í–‰ ì¶œë ¥")
    parser.add_argument("--tail", type=int, metavar="N",
                        help="ë§ˆì§€ë§‰ Nê°œ í–‰ ì¶œë ¥")
    parser.add_argument("--column", "-c", type=str,
                        help="íŠ¹ì • ì—´ì˜ í†µê³„")
    parser.add_argument("--filter", "-f", type=str,
                        help="í•„í„°ë§ (ì˜ˆ: 'column gt 100')")
    parser.add_argument("--group", "-g", type=str,
                        help="ê·¸ë£¹í™” ê¸°ì¤€ ì—´")
    parser.add_argument("--agg", type=str,
                        help="ê·¸ë£¹í™” ì‹œ ì§‘ê³„í•  ì—´")
    parser.add_argument("--hist", type=str, metavar="COLUMN",
                        help="íˆìŠ¤í† ê·¸ë¨ ì¶œë ¥")
    parser.add_argument("--corr", nargs=2, metavar=("COL1", "COL2"),
                        help="ë‘ ì—´ì˜ ìƒê´€ê³„ìˆ˜")
    parser.add_argument("--value-counts", "-v", type=str, metavar="COLUMN",
                        help="ê°’ ë¹ˆë„ ì¶œë ¥")
    parser.add_argument("--output", "-o", type=str,
                        help="ê²°ê³¼ ì €ì¥ íŒŒì¼")
    parser.add_argument("--encoding", "-e", type=str, default="utf-8",
                        help="íŒŒì¼ ì¸ì½”ë”© (ê¸°ë³¸ê°’: utf-8)")
    
    args = parser.parse_args()
    
    try:
        analyzer = DataAnalyzer(args.file, encoding=args.encoding)
        
        print(f"\nğŸ“‚ íŒŒì¼: {args.file}")
        print(f"ğŸ“‹ í–‰: {len(analyzer.data):,} | ì—´: {len(analyzer.columns)}")
        print(f"ğŸ“‘ ì—´ ëª©ë¡: {', '.join(analyzer.columns)}")
        print()
        
        # ìƒì„¸ í†µê³„
        if args.describe:
            print(analyzer.describe())
            return
        
        # ì²˜ìŒ/ë§ˆì§€ë§‰ Ní–‰
        if args.head:
            print(f"ğŸ“„ ì²˜ìŒ {args.head}ê°œ í–‰:")
            print_table(analyzer.head(args.head), analyzer.columns)
            return
        
        if args.tail:
            print(f"ğŸ“„ ë§ˆì§€ë§‰ {args.tail}ê°œ í–‰:")
            print_table(analyzer.tail(args.tail), analyzer.columns)
            return
        
        # íŠ¹ì • ì—´ í†µê³„
        if args.column:
            stats = analyzer.get_column_stats(args.column)
            
            print(f"ğŸ“Š ì—´ '{stats.name}' í†µê³„:")
            print("-" * 40)
            print(f"  íƒ€ì…: {stats.dtype}")
            print(f"  ìœ íš¨ê°’: {stats.count - stats.missing:,}")
            print(f"  ê²°ì¸¡ê°’: {stats.missing:,}")
            print(f"  ê³ ìœ ê°’: {stats.unique:,}")
            
            if stats.dtype == "numeric":
                print(f"  ìµœì†Ÿê°’: {stats.min_val:,.2f}")
                print(f"  ìµœëŒ“ê°’: {stats.max_val:,.2f}")
                print(f"  í‰ê· : {stats.mean:,.2f}")
                print(f"  ì¤‘ì•™ê°’: {stats.median:,.2f}")
                print(f"  í‘œì¤€í¸ì°¨: {stats.std_dev:,.2f}")
                print(f"  í•©ê³„: {stats.sum_val:,.2f}")
            else:
                print("  ìƒìœ„ ê°’:")
                for val, count in stats.top_values:
                    print(f"    - {val}: {count:,}")
            return
        
        # í•„í„°ë§
        if args.filter:
            parts = args.filter.split()
            if len(parts) < 3:
                print("âŒ í•„í„° í˜•ì‹: 'column condition value'")
                print("   ì¡°ê±´: eq, ne, gt, lt, ge, le, contains")
                return
            
            col, cond, val = parts[0], parts[1], " ".join(parts[2:])
            filtered = analyzer.filter(col, cond, val)
            
            print(f"ğŸ” í•„í„° ê²°ê³¼: {len(filtered):,}ê°œ í–‰")
            print_table(filtered[:20], analyzer.columns)
            
            if args.output:
                analyzer.to_csv(args.output, filtered)
                print(f"\nâœ… ì €ì¥ë¨: {args.output}")
            return
        
        # ê·¸ë£¹í™”
        if args.group:
            result = analyzer.group_by(args.group, args.agg)
            
            print(f"ğŸ“Š '{args.group}' ê¸°ì¤€ ê·¸ë£¹í™”:")
            print("-" * 60)
            
            if args.agg:
                for key, stats in sorted(result.items(), key=lambda x: x[1].get("count", 0), reverse=True)[:20]:
                    print(f"\n{key}:")
                    for stat_name, stat_val in stats.items():
                        if isinstance(stat_val, float):
                            print(f"  {stat_name}: {stat_val:,.2f}")
                        else:
                            print(f"  {stat_name}: {stat_val:,}")
            else:
                for key, count in sorted(result.items(), key=lambda x: x[1], reverse=True)[:20]:
                    print(f"  {key}: {count:,}")
            return
        
        # íˆìŠ¤í† ê·¸ë¨
        if args.hist:
            stats = analyzer.get_column_stats(args.hist)
            
            if stats.dtype != "numeric":
                print(f"âŒ '{args.hist}' ì—´ì€ ìˆ«ìí˜•ì´ ì•„ë‹™ë‹ˆë‹¤.")
                return
            
            values = []
            for row in analyzer.data:
                v = analyzer._to_numeric(row.get(args.hist, ""))
                if v is not None:
                    values.append(v)
            
            print(f"ğŸ“Š '{args.hist}' íˆìŠ¤í† ê·¸ë¨:")
            print("-" * 70)
            print(create_histogram(values))
            return
        
        # ìƒê´€ê³„ìˆ˜
        if args.corr:
            col1, col2 = args.corr
            corr = analyzer.correlation(col1, col2)
            
            if corr is not None:
                print(f"ğŸ“ˆ ìƒê´€ê³„ìˆ˜ ({col1} vs {col2}): {corr:.4f}")
                
                if abs(corr) >= 0.7:
                    strength = "ê°•í•œ"
                elif abs(corr) >= 0.4:
                    strength = "ì¤‘ê°„"
                else:
                    strength = "ì•½í•œ"
                
                direction = "ì–‘ì˜" if corr > 0 else "ìŒì˜"
                print(f"   í•´ì„: {strength} {direction} ìƒê´€ê´€ê³„")
            else:
                print("âŒ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê°’ ë¹ˆë„
        if args.value_counts:
            counts = analyzer.value_counts(args.value_counts)
            
            print(f"ğŸ“Š '{args.value_counts}' ê°’ ë¹ˆë„:")
            print("-" * 40)
            for val, count in counts[:20]:
                pct = count / len(analyzer.data) * 100
                bar = "â–ˆ" * int(pct / 2)
                print(f"  {val[:20]:20} {count:>6} ({pct:5.1f}%) {bar}")
            return
        
        # ê¸°ë³¸: ìš”ì•½ ì •ë³´
        print(analyzer.describe())
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.file}")
    except ValueError as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main()

